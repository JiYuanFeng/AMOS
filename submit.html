<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">

    <title>Services - Moderna Bootstrap Template</title>
    <meta content="" name="description">
    <meta content="" name="keywords">

    <!-- Favicons -->
    <link href="assets/img/favicon.png" rel="icon">
    <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Roboto:300,300i,400,400i,500,500i,700,700i&display=swap"
          rel="stylesheet">

    <!-- Vendor CSS Files -->
    <link href="assets/vendor/animate.css/animate.min.css" rel="stylesheet">
    <link href="assets/vendor/aos/aos.css" rel="stylesheet">
    <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
    <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
    <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
    <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

    <!-- Template Main CSS File -->
    <link href="assets/css/style.css" rel="stylesheet">
    <link href="assets/css/style2.css" rel="stylesheet">
    <!-- =======================================================
    * Template Name: Moderna - v4.8.0
    * Template URL: https://bootstrapmade.com/free-bootstrap-template-corporate-moderna/
    * Author: BootstrapMade.com
    * License: https://bootstrapmade.com/license/
    ======================================================== -->
</head>

<body>
<!-- ======= Header ======= -->
<header class="fixed-top d-flex align-items-center " id="header">
    <div class="container d-flex justify-content-between align-items-center">

        <div class="logo">
            <h1 class="text-light"><a href="index.html"><span>AMOS Benchmark</span></a></h1>
            <!-- Uncomment below if you prefer to use an image logo -->
            <!-- <a href="index.html"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->
        </div>

        <nav class="navbar" id="navbar">
            <ul>
                <li><a class="" href="index.html">Home</a></li>
                <li><a href="about.html">About</a></li>
                <li><a class="active" href="leaderboard.html">Leaderboard</a></li>
                <li><a href="paper.html">Paper</a></li>
                <li><a href="update.html">Update</a></li>
                <li><a href="https://github.com/JiYuanFeng/AMOS">Github</a></li>
                <!--          <li class="dropdown"><a href="#"><span>Drop Down</span> <i class="bi bi-chevron-down"></i></a>-->
                <!--            <ul>-->
                <!--              <li><a href="#">Drop Down 1</a></li>-->
                <!--              <li class="dropdown"><a href="#"><span>Deep Drop Down</span> <i class="bi bi-chevron-right"></i></a>-->
                <!--                <ul>-->
                <!--                  <li><a href="#">Deep Drop Down 1</a></li>-->
                <!--                  <li><a href="#">Deep Drop Down 2</a></li>-->
                <!--                  <li><a href="#">Deep Drop Down 3</a></li>-->
                <!--                  <li><a href="#">Deep Drop Down 4</a></li>-->
                <!--                  <li><a href="#">Deep Drop Down 5</a></li>-->
                <!--                </ul>-->
                <!--              </li>-->
                <!--              <li><a href="#">Drop Down 2</a></li>-->
                <!--              <li><a href="#">Drop Down 3</a></li>-->
                <!--              <li><a href="#">Drop Down 4</a></li>-->
                <!--            </ul>-->
                <!--          </li>-->
                <!--          <li><a href="contact.html">Contact Us</a></li>-->
                <!--        </ul>-->
                <!--        <i class="bi bi-list mobile-nav-toggle"></i>-->
        </nav><!-- .navbar -->

    </div>
</header><!-- End Header -->


<main id="main">
    <div class="row">
        <div class="col-md-12 col-lg-12">
            <div , class="content" style="padding-top: 0em; padding-left: 0em">
                <!-- ======= Our Services Section ======= -->
                <section class="breadcrumbs">
                    <div class="container">
                        <div class="d-flex justify-content-between align-items-center">
                            <h2></h2>
                            <ol>
                                <li><a href="index.html">Home</a></li>
                                <li>Leaderboard</li>
                            </ol>
                        </div>
                    </div>
                </section><!-- End Our Services Section -->
            </div>
        </div>
    </div>
    <div class="section">
        <div class="container">
            <div class="row">

                <div class="col-md-10">
                    <div class="content" style="padding-top: 2.2em; padding-left: 1em ">
                        <h3 id="overview"><a class="title-anchor-link" href="#overview">#</a> Overview</h3>

                        <p>Thank you for submitting to the WILDS leaderboards.</p>

                        <p>We welcome submissions of new algorithms and/or models, and we encourage contributors to test
                            their new methods on as many datasets as applicable. This is valuable even if (or especially
                            if) your method performs well on some datasets but not others.</p>

                        <p>We also welcome re-implementations of existing methods. On the leaderboards, we distinguish
                            between official submissions (made by the authors of a method) and unofficial submissions
                            (re-implementations by other contributors). Unofficial submissions are equally valuable,
                            especially if the re-implementations achieve better performance than the original
                            implementations because of better tuning or simple tweaks.</p>

                        <p>All submissions must use the dataset classes and evaluators in the WILDS package. In
                            addition, they must report results on multiple replicates: 5 random seeds for CivilComments;
                            10 random seeds for Camelyon17; 5 folds for PovertyMap; and 3 random seeds for all other
                            datasets.</p>

                        <p>Submissions fall into two categories: standard submissions and non-standard submissions.</p>

                        <h3 id="standard-submissions"><a class="title-anchor-link" href="#standard-submissions">#</a>
                            Standard submissions</h3>

                        <p>Standard submissions must follow these guidelines:</p>
                        <ol>
                            <li>Results must be reported on at least 3 random seeds. The following datasets must have
                                more replicates: 5 random seeds for CivilComments; 10 random seeds for Camelyon17; and 5
                                folds for PovertyMap.
                            </li>
                            <li>The test set must not be used in any form for model training or selection.</li>
                            <li>The validation set must be either the official out-of-distribution (OOD) validation set
                                or,
                                if applicable, the official in-distribution (ID) validation set.
                            </li>
                            <li>The validation set should only be used for hyperparameter selection. For example, after
                                hyperparameters have been selected, do not combine the validation set with the training
                                set and retrain the model.
                            </li>
                            <li>Training and model selection should not use any additional data, labeled or unlabeled,
                                beyond the official training and validation data.
                            </li>
                            <li>To avoid unintended adaptation, models should not use batch statistics during
                                evaluation. BatchNorm is accepted in its default mode (where it uses batch statistics
                                during training, and then fixes them during evaluation).
                            </li>
                            <li>Other dataset-specific guidelines:
                                <ul>
                                    <li>For Camelyon17, models that only use labeled data should not use color
                                        augmentation. Models that use unlabeled data can use augmentation, since
                                        unlabeled data methods typically rely on augmentation. All models should not be
                                        pretrained on external data.
                                    </li>
                                    <li>For iWildCam, models should not use off-the-shelf detectors (e.g., MegaDetector)
                                        that have been trained on external data.
                                    </li>
                                </ul>
                            </li>
                        </ol>

                        <h3 id="non-standard-submissions"><a class="title-anchor-link" href="#non-standard-submissions">#</a>
                            Non-standard submissions</h3>

                        <p>Non-standard submissions only need to follow the first two guidelines from above:</p>
                        <ol>
                            <li>Results must be reported on at least 3 random seeds. The following datasets must have
                                more replicates: 5 random seeds for CivilComments; 10 random seeds for Camelyon17; and 5
                                folds for PovertyMap.
                            </li>
                            <li>The test set must not be used in any form for model training or selection.</li>
                        </ol>

                        <p>These submissions will be differentiated from standard submissions in our leaderboards.
                            They are meant for the community to try out different approaches to solving these tasks.
                            Examples of non-standard submissions might include:</p>
                        <ul>
                            <li>Using unlabeled data from external sources</li>
                            <li>Specialized methods for particular datasets/domains, such as color augmentation for
                                Camelyon17
                            </li>
                            <li>Using leave-one-domain-out cross-validation instead of the fixed OOD validation set</li>
                        </ul>

                        <h3 id="making-a-submission"><a class="title-anchor-link" href="#making-a-submission">#</a>
                            Making a submission</h3>

                        <p>Submitting to the WILDS leaderboard consists of two steps: first, uploading your predictions
                            in <code class="language-plaintext highlighter-rouge">.csv</code> format, and second,
                            filling up our submission form.</p>

                        <h4 id="submission-formatting"><a class="title-anchor-link" href="#submission-formatting">#</a>
                            Submission formatting</h4>

                        <p>Please submit your predictions in <code
                                class="language-plaintext highlighter-rouge">.csv</code> format for all datasets except
                            GlobalWheat, and <code class="language-plaintext highlighter-rouge">.pth</code> format for
                            the GlobalWheat dataset.
                            The example scripts in the <code
                                    class="language-plaintext highlighter-rouge">examples/</code> folder will
                            automatically train models and save their predictions in the right format; see the
                            <a href="/get_started/">Get Started</a> page for information on how to use these scripts.
                        </p>

                        <p>If you are not using the example scripts, see the last section on this page for details on
                            the expected format.</p>

                        <h4 id="step-1-uploading-your-predictions"><a class="title-anchor-link"
                                                                      href="#step-1-uploading-your-predictions">#</a>
                            Step 1: Uploading
                            your predictions</h4>

                        <p>Upload a .tar.gz or .zip file containing your predictions in the format specified above. Feel
                            free to use any standard host for your file (Google Drive, Dropbox, etc.).</p>

                        <p><strong>Check that your predictions are valid by running the <a
                                href="https://github.com/p-lambda/wilds/blob/main/examples/evaluate.py">evaluate.py</a>
                            script on them.</strong> To do so, run <code class="language-plaintext highlighter-rouge">python3
                            examples/evaluate.py [path_to_predictions] [path_to_output_results] --root_dir
                            [path_to_data]</code>.</p>

                        <p>Please upload a separate .tar.gz or .zip file per method that you are submitting. For
                            example, if you are submitting algorithm A and algorithm B, both of which are evaluated on 6
                            different datasets, then you should submit two different .tar.gz or .zip files: one
                            corresponding to algorithm A (and containing predictions for all 6 datasets) and the other
                            corresponding to algorithm B (also containing predictions for all 6 datasets.)</p>

                        <h4 id="step-2-filling-out-the-submission-form"><a
                                class="title-anchor-link" href="#step-2-filling-out-the-submission-form">#</a> Step 2:
                            Filling out the submission form</h4>

                        <p>Next, fill up the
                            <a href="https://forms.gle/TLyvXetBUnJxkFFi7">submission form</a>. You will need to fill out
                            one form per .tar.gz/.zip file submitted. The form will ask for the URL to your submission
                            file.</p>

                        <p>Once these steps have been completed, we will evaluate the predictions using the <a
                                href="https://github.com/p-lambda/wilds/blob/main/examples/evaluate.py">evaluate.py</a>
                            script and update the leaderboard within a week.</p>

                        <h4 id="detailed-submission-format"><a class="title-anchor-link"
                                                               href="#detailed-submission-format">#</a> Detailed
                            submission
                            format</h4>

                        <p>If you are manually generating the submission without using the example scripts, it should be
                            structured in the following way:</p>
                        <ul>
                            <li>Each submission should have its own predictions folder (the name of the folder does not
                                matter).
                            </li>
                            <li>Every dataset that you have results for should have its own subfolder: <code
                                    class="language-plaintext highlighter-rouge">amazon</code>, <code
                                    class="language-plaintext highlighter-rouge">camelyon17</code>, <code
                                    class="language-plaintext highlighter-rouge">civilcomments</code>, <code
                                    class="language-plaintext highlighter-rouge">fmow</code>, <code
                                    class="language-plaintext highlighter-rouge">iwildcam</code>, <code
                                    class="language-plaintext highlighter-rouge">ogb-molpcba</code>, <code
                                    class="language-plaintext highlighter-rouge">poverty</code>, <code
                                    class="language-plaintext highlighter-rouge">py150</code>.
                            </li>
                            <li>In each directory, there should be one <code
                                    class="language-plaintext highlighter-rouge">.csv</code> or <code
                                    class="language-plaintext highlighter-rouge">.pth</code> per available evaluation
                                split (e.g., <code class="language-plaintext highlighter-rouge">val</code>, <code
                                        class="language-plaintext highlighter-rouge">test</code>, <code
                                        class="language-plaintext highlighter-rouge">id-val</code>, <code
                                        class="language-plaintext highlighter-rouge">id-test</code>) and replicate.
                                Please use the following naming convention: <code
                                        class="language-plaintext highlighter-rouge">{dataset}_split:{split}_seed:{seed}_epoch:{epoch}_pred.csv</code>.
                                It does not matter what <code
                                        class="language-plaintext highlighter-rouge">{epoch}</code> is, so long as there
                                is only one epoch selected per dataset, split, and seed. For <code
                                        class="language-plaintext highlighter-rouge">poverty</code>, replace <code
                                        class="language-plaintext highlighter-rouge">seed</code> with <code
                                        class="language-plaintext highlighter-rouge">fold</code>.
                            </li>
                        </ul>

                        <p>As an example, this would be a valid predictions directory:</p>

                        <div class="language-plaintext highlighter-rouge">
                            <div class="highlight"><pre class="highlight"><code>predictions [the name of the top-level folder is arbitrary]
|-- iwildcam
|   |-- iwildcam_split:id_test_seed:0_epoch:best_pred.csv
|   |-- iwildcam_split:id_val_seed:0_epoch:best_pred.csv
|   |-- iwildcam_split:test_seed:0_epoch:best_pred.csv
|   |-- iwildcam_split:val_seed:0_epoch:best_pred.csv
|   |-- iwildcam_split:id_test_seed:1_epoch:best_pred.csv
|   |-- iwildcam_split:id_val_seed:1_epoch:best_pred.csv
|   |-- iwildcam_split:test_seed:1_epoch:best_pred.csv
|   |-- iwildcam_split:val_seed:1_epoch:best_pred.csv
|   |-- iwildcam_split:id_test_seed:2_epoch:best_pred.csv
|   |-- iwildcam_split:id_val_seed:2_epoch:best_pred.csv
|   |-- iwildcam_split:test_seed:2_epoch:best_pred.csv
|   |-- iwildcam_split:val_seed:2_epoch:best_pred.csv
|-- poverty
|   |-- poverty_split:id_test_fold:A_epoch:best_pred.csv
|   |-- poverty_split:id_val_fold:A_epoch:best_pred.csv
|   |-- poverty_split:test_fold:A_epoch:best_pred.csv
|   |-- poverty_split:val_fold:A_epoch:best_pred.csv
|   |-- poverty_split:id_test_fold:B_epoch:best_pred.csv
|   |-- poverty_split:id_val_fold:B_epoch:best_pred.csv
|   |-- poverty_split:test_fold:B_epoch:best_pred.csv
|   |-- poverty_split:val_fold:B_epoch:best_pred.csv
|   |-- poverty_split:id_test_fold:C_epoch:best_pred.csv
|   |-- poverty_split:id_val_fold:C_epoch:best_pred.csv
|   |-- poverty_split:test_fold:C_epoch:best_pred.csv
|   |-- poverty_split:val_fold:C_epoch:best_pred.csv
|   |-- poverty_split:id_test_fold:D_epoch:best_pred.csv
|   |-- poverty_split:id_val_fold:D_epoch:best_pred.csv
|   |-- poverty_split:test_fold:D_epoch:best_pred.csv
|   |-- poverty_split:val_fold:D_epoch:best_pred.csv
|   |-- poverty_split:id_test_fold:E_epoch:best_pred.csv
|   |-- poverty_split:id_val_fold:E_epoch:best_pred.csv
|   |-- poverty_split:test_fold:E_epoch:best_pred.csv
|   |-- poverty_split:val_fold:E_epoch:best_pred.csv
...
</code></pre>
                            </div>
                        </div>

                        <p>Each <code class="language-plaintext highlighter-rouge">.csv</code> should be structured in
                            the following way:</p>
                        <ul>
                            <li>Each row should correspond to an example, in the order of the dataset (i.e., the first
                                row should correspond to the first example of the dataset, etc.).
                            </li>
                            <li>Specifically, each row should contain the entry of <code
                                    class="language-plaintext highlighter-rouge">y_pred</code> corresponding to that
                                example. The format of <code class="language-plaintext highlighter-rouge">y_pred</code>
                                should be exactly what is passed to that dataset’s <code
                                        class="language-plaintext highlighter-rouge">eval</code> function. The columns
                                correspond to the different dimensions of <code
                                        class="language-plaintext highlighter-rouge">y_pred</code>. For example, binary
                                classification datasets will have only one column (of integers), while <code
                                        class="language-plaintext highlighter-rouge">ogb-molpcba</code> will have 128
                                columns (of logits), and <code class="language-plaintext highlighter-rouge">py150</code>
                                will have 255 columns (of integers).
                            </li>
                        </ul>

                        <p>For example, <code class="language-plaintext highlighter-rouge">iwildcam_split:id_test_seed:0_epoch:best_pred.csv</code>
                            might look like</p>
                        <div class="language-plaintext highlighter-rouge">
                            <div class="highlight"><pre class="highlight"><code>4
172
0
24
...
</code></pre>
                            </div>
                        </div>
                        <p>representing a prediction of class 4 for the first example, class 172 for the second example,
                            etc.</p>

                        <p>For GlobalWheat-WILDS, the <code class="language-plaintext highlighter-rouge">.pth</code>
                            should be structured in the following way:</p>
                        <ul>
                            <li>The <code class="language-plaintext highlighter-rouge">.pth</code> should contain a list
                                with one element per example.
                            </li>
                            <li>Each element of the list should be a dictionary containing at least the following keys:
                                <code class="language-plaintext highlighter-rouge">boxes</code> and <code
                                        class="language-plaintext highlighter-rouge">scores</code>.
                            </li>
                            <li><code class="language-plaintext highlighter-rouge">boxes</code> should be a <code
                                    class="language-plaintext highlighter-rouge">M x 4</code> tensor where <code
                                    class="language-plaintext highlighter-rouge">M</code> is the number of bounding
                                boxes predicted in the example, and the columns correspond to <code
                                        class="language-plaintext highlighter-rouge">(x_min, y_min, x_max, y_max)</code>,
                                where the coordinates are not normalized.
                            </li>
                            <li><code class="language-plaintext highlighter-rouge">scores</code> should be a <code
                                    class="language-plaintext highlighter-rouge">M</code>-dimensional tensor containing
                                the predicted probability of the corresponding bounding box representing a wheat head.
                            </li>
                        </ul>

                    </div><!-- /.content -->
                </div><!-- /.col -->
            </div><!-- /.row -->
        </div><!-- /.container -->
    </div>
</main><!-- End #main -->

<a class="back-to-top d-flex align-items-center justify-content-center" href="#"><i
        class="bi bi-arrow-up-short"></i></a>

<!-- Vendor JS Files -->
<script src="assets/vendor/purecounter/purecounter.js"></script>
<script src="assets/vendor/aos/aos.js"></script>
<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
<script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
<script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
<script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
<script src="assets/vendor/php-email-form/validate.js"></script>

<!-- Template Main JS File -->
<script src="assets/js/main.js"></script>

</body>

</html>